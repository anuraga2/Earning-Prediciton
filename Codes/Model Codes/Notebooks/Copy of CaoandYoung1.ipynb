{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2v552lBV_2sc"
   },
   "source": [
    "## Loading Relevant Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1626918805724,
     "user": {
      "displayName": "Anurag Anand",
      "photoUrl": "",
      "userId": "08753308162815991310"
     },
     "user_tz": 300
    },
    "id": "F97W6_M9__68"
   },
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "# other imports\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import time\n",
    "\n",
    "# plotly imports\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbo7D9BIAXSk"
   },
   "source": [
    "### Reading Data and some basic manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1362,
     "status": "ok",
     "timestamp": 1626918811310,
     "user": {
      "displayName": "Anurag Anand",
      "photoUrl": "",
      "userId": "08753308162815991310"
     },
     "user_tz": 300
    },
    "id": "Wa3Vj8HhAq6d"
   },
   "outputs": [],
   "source": [
    "## Reading the Parquet file and converting it to a pandas dataframe\n",
    "df = pq.read_table('CaoYouSample.parquet')\n",
    "df = df.to_pandas()\n",
    "\n",
    "## Data Cleaning steps before we jump into test - train split and transformations\n",
    "df_new = df.copy()\n",
    "rem_cols = ['CONM', 'TIC', 'CUSIP','FiscalYearEnd', 'FYEND_plus_3mos','LPERMNO','FYR','SIC','DATADATE']\n",
    "df_new.drop(rem_cols, axis = 1, inplace = True)\n",
    "df_new = df_new.drop_duplicates()\n",
    "df_new = df_new.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-xEbGwJD2yp"
   },
   "source": [
    "### Test - Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1626918814397,
     "user": {
      "displayName": "Anurag Anand",
      "photoUrl": "",
      "userId": "08753308162815991310"
     },
     "user_tz": 300
    },
    "id": "U6ZtRbtmEGc3"
   },
   "outputs": [],
   "source": [
    "X_IncomeStmt = ['SALE', 'COGS', 'XSGA', 'XAD', 'XRD', 'DP', 'XINT', 'NOPIO', 'TXT', 'XIDO', 'E', 'DVC']\n",
    "X_IncomeStmt += [f'{feature}_D1' for feature in X_IncomeStmt]\n",
    "X_BalanceSheet = ['CHE', 'INVT', 'RECT', 'ACT', 'PPENT', 'IVAO', 'INTAN', 'AT', 'AP', 'DLC', 'TXP', 'LCT', 'DLTT', 'LT', 'CEQ']\n",
    "X_BalanceSheet += [f'{feature}_D1' for feature in X_BalanceSheet]\n",
    "X_CashFlowStmt = ['CFO', 'CFO_D1']\n",
    "\n",
    "X = X_IncomeStmt + X_BalanceSheet + X_CashFlowStmt\n",
    "y = ['E_F1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "84jiJ-uwm6-0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2014rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012rf.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "C:\\Users\\anura\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011rf.pkl\n"
     ]
    }
   ],
   "source": [
    "cv_error = {} # Dictionary to store cross validation error data\n",
    "year_list = [2016, 2015, 2014, 2013, 2012, 2011]\n",
    "for year in year_list:\n",
    "\n",
    "    # train split\n",
    "    train_X = df_new.loc[(df_new['FYEAR'] >= (year-10)) & (df_new['FYEAR'] <= (year-1)), X]\n",
    "    train_y = df_new.loc[(df_new['FYEAR'] >= (year-10)) & (df_new['FYEAR'] <= (year-1)), y]\n",
    "\n",
    "    # test split\n",
    "    test_X = df_new.loc[df_new['FYEAR'] == year, X]\n",
    "    test_y = df_new.loc[df_new['FYEAR'] == year, y]\n",
    "    \n",
    "    parameters = {'max_features':['auto'],'max_depth':[20,25,30,35],'min_samples_leaf':[15,20,25,50]}\n",
    "    \n",
    "    # setting up the parameter space\n",
    "    rf_mod = RandomForestRegressor(n_estimators=500, criterion='mse', oob_score=True, n_jobs=-1, random_state=10)\n",
    "\n",
    "    # Setting up the Grid Search object\n",
    "    grid_search = GridSearchCV(rf_mod, parameters, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "    # Fitting the model\n",
    "    grid_search.fit(train_X, train_y)\n",
    "\n",
    "    # declaring empty list to append model training error\n",
    "    lst = []\n",
    "    cvres = grid_search.cv_results_\n",
    "\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        lst.append((np.sqrt(-mean_score), params))\n",
    "\n",
    "    # appending the year data to the emp\n",
    "    if year not in cv_error:\n",
    "        cv_error[year] = lst\n",
    "\n",
    "    # declaring a string for the model name\n",
    "    model_name = str(year)+\"rf.pkl\"\n",
    "\n",
    "    # saving the model\n",
    "    year_mod = grid_search.best_estimator_\n",
    "\n",
    "    # saving the model to drive\n",
    "    joblib.dump(year_mod,model_name)\n",
    "\n",
    "    # print(file name)\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year: 2016, Least CV Error: 66.07376762767734, features: {'max_depth': 35, 'max_features': 'auto', 'min_samples_leaf': 15}\n",
      "Year: 2015, Least CV Error: 79.08663197900759, features: {'max_depth': 20, 'max_features': 'auto', 'min_samples_leaf': 50}\n",
      "Year: 2014, Least CV Error: 85.15852247227367, features: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 15}\n",
      "Year: 2013, Least CV Error: 88.72601806933635, features: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 15}\n",
      "Year: 2012, Least CV Error: 93.16207712119427, features: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 15}\n",
      "Year: 2011, Least CV Error: 93.395949345559, features: {'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 15}\n"
     ]
    }
   ],
   "source": [
    "for year in year_list:\n",
    "    \n",
    "    smallest_error = 1000\n",
    "    for item in cv_error[year]:\n",
    "        if item[0] < smallest_error:\n",
    "            smallest_error = item[0]\n",
    "            features = item[1]\n",
    "\n",
    "    print(\"Year: {}, Least CV Error: {}, features: {}\".format(year, smallest_error, features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp_dict = {}\n",
    "for year in year_list:\n",
    "    file_name = str(year) + \"rf.pkl\"\n",
    "    mod_file = joblib.load(file_name)\n",
    "    \n",
    "    if year not in feature_imp_dict:\n",
    "        feature_imp_dict[year] = sorted(zip(mod_file.feature_importances_, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1, list2 = zip(*feature_imp_dict[2016])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM56SUCsftHCsgBhcCdhdc7",
   "collapsed_sections": [],
   "mount_file_id": "1LsfYtYDlMl6Hzr18nghD_em5R4kgEFE9",
   "name": "Copy of CaoandYoung1.ipynb",
   "provenance": [
    {
     "file_id": "1LsfYtYDlMl6Hzr18nghD_em5R4kgEFE9",
     "timestamp": 1626918904592
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
